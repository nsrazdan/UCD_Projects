Started with k = 3 days ago.
Residuals:
    Min      1Q  Median      3Q     Max 
-10.067  -1.782   0.091   1.962   9.253 

Coefficients:
                   Estimate Std. Error t value Pr(>|t|)    
(Intercept)         0.07319    1.10620   0.066   0.9473    
trainingdata[, 1]   0.54128    0.27620   1.960   0.0508 .  
trainingdata[, 2]  -0.20195    0.21593  -0.935   0.3503    
trainingdata[, 3]  -0.78688    2.93231  -0.268   0.7886    
trainingdata[, 4]   4.21856    3.38474   1.246   0.2135    
trainingdata[, 5]   1.77068    2.98470   0.593   0.5534    
trainingdata[, 6]   0.01175    0.30585   0.038   0.9694    
trainingdata[, 7]  -0.34837    0.23040  -1.512   0.1314    
trainingdata[, 8]   0.02070    4.11050   0.005   0.9960    
trainingdata[, 9]  -1.62983    4.71418  -0.346   0.7298    
trainingdata[, 10]  0.26755    4.11411   0.065   0.9482    
trainingdata[, 11] -0.08790    0.29112  -0.302   0.7629    
trainingdata[, 12]  1.04640    0.21707   4.821 2.15e-06 ***
trainingdata[, 13] -0.34226    2.94653  -0.116   0.9076    
trainingdata[, 14] -1.45096    3.37178  -0.430   0.6672    
trainingdata[, 15] -0.14586    2.96331  -0.049   0.9608    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 3.323 on 346 degrees of freedom
Multiple R-squared:  0.9147,	Adjusted R-squared:  0.911 
F-statistic: 247.2 on 15 and 346 DF,  p-value: < 2.2e-16


k = 4

Residuals:
    Min      1Q  Median      3Q     Max 
-8.2758 -1.2746  0.1854  1.4157  7.6805 

Coefficients:
                   Estimate Std. Error t value Pr(>|t|)    
(Intercept)         1.70210    0.88060   1.933 0.054080 .  
trainingdata[, 1]   0.02766    0.20875   0.133 0.894647    
trainingdata[, 2]   0.04573    0.16224   0.282 0.778228    
trainingdata[, 3]   1.91050    2.18347   0.875 0.382201    
trainingdata[, 4]   4.18570    2.52412   1.658 0.098183 .  
trainingdata[, 5]   3.02149    2.23237   1.353 0.176798    
trainingdata[, 6]   0.34075    0.22960   1.484 0.138700    
trainingdata[, 7]  -0.16819    0.17382  -0.968 0.333938    
trainingdata[, 8]  -2.36236    3.05720  -0.773 0.440224    
trainingdata[, 9]  -0.39989    3.50552  -0.114 0.909246    
trainingdata[, 10] -0.25745    3.06447  -0.084 0.933098    
trainingdata[, 11]  0.09634    0.22964   0.420 0.675106    
trainingdata[, 12] -0.30445    0.17279  -1.762 0.078975 .  
trainingdata[, 13] -0.10289    3.06252  -0.034 0.973219    
trainingdata[, 14] -1.34611    3.50521  -0.384 0.701195    
trainingdata[, 15] -0.87492    3.06200  -0.286 0.775254    
trainingdata[, 16]  0.23623    0.21902   1.079 0.281550    
trainingdata[, 17]  0.56971    0.16322   3.490 0.000546 ***
trainingdata[, 18]  0.12263    2.19418   0.056 0.955463    
trainingdata[, 19] -1.29385    2.50835  -0.516 0.606318    
trainingdata[, 20] -0.07837    2.20969  -0.035 0.971728    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 2.47 on 340 degrees of freedom
Multiple R-squared:  0.9271,	Adjusted R-squared:  0.9228 
F-statistic: 216.2 on 20 and 340 DF,  p-value: < 2.2e-16



k = 2
Residuals:
    Min      1Q  Median      3Q     Max 
-9.0067 -1.2958  0.1035  1.4511  7.2918 

Coefficients:
                   Estimate Std. Error t value Pr(>|t|)    
(Intercept)         1.66826    0.78070   2.137 0.033296 *  
trainingdata[, 1]   0.58618    0.20764   2.823 0.005028 ** 
trainingdata[, 2]  -0.56300    0.16118  -3.493 0.000538 ***
trainingdata[, 3]   0.09404    2.25335   0.042 0.966734    
trainingdata[, 4]   1.92441    2.59972   0.740 0.459649    
trainingdata[, 5]   0.89493    2.29386   0.390 0.696668    
trainingdata[, 6]   0.30058    0.22055   1.363 0.173789    
trainingdata[, 7]   0.52687    0.16547   3.184 0.001582 ** 
trainingdata[, 8]  -1.10347    2.24024  -0.493 0.622627    
trainingdata[, 9]  -0.88764    2.59042  -0.343 0.732058    
trainingdata[, 10]  1.21120    2.26554   0.535 0.593251    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 2.555 on 352 degrees of freedom
Multiple R-squared:  0.9203,	Adjusted R-squared:  0.918 
F-statistic: 406.4 on 10 and 352 DF,  p-value: < 2.2e-16

k = 60

Residuals:
         1          2          3          4          5          6          7          8          9         10         11         12         13         14         15 
-3.957e-01 -3.837e-01 -3.148e-02  2.258e-02  2.489e-01  4.923e-01  7.011e-01 -4.968e-01 -1.050e-01 -3.082e-03 -2.201e-02 -2.052e-01  3.699e-02 -1.114e-01 -1.011e-01 
        16         17         18         19         20         21         22         23         24         25         26         27         28         29         30 
 1.904e-01 -8.053e-02 -1.023e-01 -1.685e-01  2.344e-01  2.332e-02  5.013e-02 -6.160e-02  1.842e-01  7.009e-02 -1.123e-02  3.751e-02  7.891e-02 -3.085e-02 -6.024e-02 
        31         32         33         34         35         36         37         38         39         40         41         42         43         44         45 
-2.168e-15 -3.365e-16  2.255e-16 -1.877e-15 -7.598e-16  3.463e-15 -2.685e-15  5.239e-16  1.478e-15 -1.405e-15  3.227e-16  3.612e-15 -2.016e-15 -2.547e-15  1.193e-15 
        46         47         48         49         50         51         52         53         54         55         56         57         58         59         60 
 1.856e-15 -7.043e-16 -2.488e-15 -1.169e-15  2.828e-15 -4.753e-16  5.586e-16 -3.036e-15  1.877e-15  2.096e-15 -3.591e-15  1.922e-15  1.974e-15 -3.185e-15  5.645e-15 
        61         62         63         64         65         66         67         68         69         70         71         72         73         74         75 
-4.489e-15  2.810e-16  1.214e-15 -3.796e-15  3.258e-15 -1.950e-15  3.476e-15 -1.853e-15 -8.153e-16  2.096e-15  1.006e-16 -8.327e-16 -8.327e-17  1.388e-16  2.436e-15 
        76         77         78         79         80         81         82         83         84         85         86         87         88         89         90 
-3.393e-15  7.008e-16  4.219e-15  8.916e-16 -8.779e-02  3.093e-01 -1.885e-01  4.845e-02 -3.354e-01  1.959e-01  2.312e-02 -2.709e-02 -6.070e-02  1.582e-01  1.050e-01 
        91         92         93         94         95         96         97         98         99        100        101        102        103        104        105 
-3.798e-02 -1.946e-02 -3.074e-02 -8.527e-02  2.061e-01 -1.061e-01  5.675e-04 -1.637e-01  2.999e-01  9.151e-01  2.254e-02 -2.707e-01 -5.652e-01  8.928e-02 -3.393e-01 
       106        107        108        109        110        111        112        113        114        115        116        117        118        119        120 
 2.400e-01 -6.682e-01 -1.814e-01 -6.273e-01  1.319e-01  4.942e-01  2.749e-01  2.332e-02  5.013e-02 -6.160e-02  1.842e-01  7.009e-02 -1.123e-02  3.751e-02  7.891e-02 
       121        122        123        124        125        126        127        128        129        130        131        132        133        134        135 
-3.085e-02 -6.024e-02 -3.272e-15  2.456e-15 -4.198e-16 -2.637e-15  3.084e-15  9.506e-16 -4.753e-16 -1.003e-15  2.342e-15  1.742e-15 -2.821e-15  1.318e-15 -3.480e-15 
       136        137        138        139        140        141        142        143        144        145        146        147        148        149        150 
 1.780e-15 -6.384e-16  5.516e-16  2.845e-16 -3.157e-16 -2.612e-15  2.987e-15 -9.541e-16  4.684e-16 -5.013e-15  2.141e-15  3.431e-15 -3.598e-15  3.521e-15 -8.847e-16 
       151        152        153        154        155        156        157        158        159        160        161        162        163        164        165 
-5.655e-16  4.344e-15 -2.921e-15  1.249e-16  1.450e-15 -4.274e-15  3.966e-15 -2.665e-15  5.315e-15 -2.023e-15  2.845e-16  3.816e-16  6.002e-16 -4.476e-16 -8.639e-16 
       166        167        168        169        170        171        172        173        174        175        176        177        178        179        180 
-1.717e-15  2.991e-15 -1.655e-15  1.631e-16  4.653e-15  1.700e-16 -3.301e-02 -5.349e-02  1.821e-01 -1.402e-02 -7.665e-03 -1.399e-01 -1.483e-02  8.516e-02 -1.470e-01 
       181        182        183        184        185        186        187        188        189        190        191        192        193        194        195 
 1.680e-01 -2.397e-01  3.967e-01 -3.762e-01  4.273e-01  3.512e-02  1.529e-01  5.455e-02 -1.979e-01  4.073e-02  2.890e-02  8.333e-02 -3.500e-01 -4.816e-01 -5.152e-01 
       196        197        198        199        200        201        202        203        204        205        206        207        208        209        210 
 2.503e-01  4.561e-01 -1.991e-01 -1.663e-01  2.887e-01 -3.460e-01  1.551e-01  1.141e-01  5.441e-01 -4.982e-01  3.685e-02  2.332e-02  5.013e-02 -6.160e-02  1.842e-01 
       211        212        213        214        215        216        217        218        219        220        221        222        223        224        225 
 7.009e-02 -1.123e-02  3.751e-02  7.891e-02 -3.085e-02 -6.024e-02 -4.413e-15  7.806e-16 -1.166e-15 -1.346e-15  2.363e-15  3.213e-15  1.065e-15 -3.521e-15  9.888e-16 
       226        227        228        229        230        231        232        233        234        235        236        237        238        239        240 
 3.518e-15 -2.800e-15 -6.939e-18 -4.233e-15  2.949e-16  1.978e-16  1.842e-15 -8.361e-16  3.955e-16 -1.266e-15  2.547e-15 -1.263e-15 -1.648e-15 -4.958e-15  4.090e-15 
       241        242        243        244        245        246        247        248        249        250        251        252        253        254        255 
 3.993e-15 -3.744e-15  2.855e-15 -1.360e-15 -8.223e-16  5.929e-15 -5.697e-15  1.475e-15  1.492e-15 -4.653e-15  4.111e-15 -1.842e-15  4.167e-15 -1.141e-15 -3.782e-16 
       256        257        258        259        260        261        262        263        264        265        266        267        268        269        270 
-2.186e-16  9.368e-16  3.608e-16 -4.441e-16 -3.293e-15  3.882e-15 -1.003e-15 -1.422e-15  3.754e-15  1.110e-15 -1.162e-01 -5.490e-01 -1.302e-01 -5.566e-02  3.527e-01 
       271        272        273        274        275        276        277        278        279        280        281        282        283        284        285 
 2.641e-01  2.611e-01 -2.415e-02  3.680e-01 -4.086e-01 -1.940e-01 -7.909e-02 -2.855e-01  3.811e-01 -1.705e-02  3.888e-01 -2.489e-01  7.401e-01  2.144e-01 -7.529e-02 
       286        287        288        289        290        291        292        293        294        295        296        297        298        299        300 
-2.208e-02 -9.235e-02  1.827e-01 -2.784e-01  1.421e-01 -7.981e-01  8.490e-02 -9.271e-02  3.564e-01 -5.496e-01  2.332e-02  5.013e-02 -6.160e-02  1.842e-01  7.009e-02 
       301        302        303        304        305 
-1.123e-02  3.751e-02  7.891e-02 -3.085e-02 -6.024e-02 

Coefficients:
                     Estimate Std. Error t value Pr(>|t|)  
(Intercept)         102.32286   80.24079   1.275   0.2713  
trainingdata[, 1]    -1.96694    1.50940  -1.303   0.2625  
trainingdata[, 2]     1.84981    1.32098   1.400   0.2340  
trainingdata[, 3]   -28.73817   18.19113  -1.580   0.1893  
trainingdata[, 4]   -22.17501   14.50504  -1.529   0.2010  
trainingdata[, 5]    -7.68512    7.39387  -1.039   0.3573  
trainingdata[, 6]    -1.88613    1.45377  -1.297   0.2643  
trainingdata[, 7]     1.63415    1.15699   1.412   0.2307  
trainingdata[, 8]   -22.33433   21.11370  -1.058   0.3498  
trainingdata[, 9]   -25.16924   16.21086  -1.553   0.1955  
trainingdata[, 10]  -13.20685    9.97918  -1.323   0.2563  
trainingdata[, 11]   -0.33562    1.68115  -0.200   0.8515  
trainingdata[, 12]    0.44118    1.40668   0.314   0.7695  
trainingdata[, 13]   -4.35932   16.65136  -0.262   0.8064  
trainingdata[, 14]   -0.08787   14.73555  -0.006   0.9955  
trainingdata[, 15]   -1.02905   14.26643  -0.072   0.9460  
trainingdata[, 16]   -1.03578    1.16937  -0.886   0.4258  
trainingdata[, 17]    1.06009    0.98634   1.075   0.3430  
trainingdata[, 18]    1.20590   17.49638   0.069   0.9484  
trainingdata[, 19]   -0.42725   14.05016  -0.030   0.9772  
trainingdata[, 20]  -11.11589   10.96871  -1.013   0.3682  
trainingdata[, 21]    0.43123    1.48356   0.291   0.7858  
trainingdata[, 22]   -0.69645    1.28069  -0.544   0.6155  
trainingdata[, 23]   24.52979   14.87153   1.649   0.1744  
trainingdata[, 24]   12.81657    9.74568   1.315   0.2588  
trainingdata[, 25]   10.87787    9.67364   1.124   0.3237  
trainingdata[, 26]    1.86665    2.46401   0.758   0.4909  
trainingdata[, 27]   -1.54658    2.21983  -0.697   0.5243  
trainingdata[, 28]   24.50838   17.07324   1.435   0.2245  
trainingdata[, 29]   14.35234   12.27697   1.169   0.3073  
trainingdata[, 30]    3.75368    9.81342   0.383   0.7215  
trainingdata[, 31]    4.30836    1.51395   2.846   0.0466 *
trainingdata[, 32]   -3.53932    1.27886  -2.768   0.0505 .
trainingdata[, 33]   19.44909   15.55552   1.250   0.2793  
trainingdata[, 34]   14.89076   11.58587   1.285   0.2681  
trainingdata[, 35]   13.01967    6.35734   2.048   0.1099  
trainingdata[, 36]    0.22755    1.34964   0.169   0.8743  
trainingdata[, 37]    0.59550    1.11819   0.533   0.6225  
trainingdata[, 38]  -14.94767   19.57150  -0.764   0.4876  
trainingdata[, 39]   -5.85748   13.23910  -0.442   0.6810  
trainingdata[, 40]   -5.42643    6.47343  -0.838   0.4491  
trainingdata[, 41]    1.33663    1.31825   1.014   0.3680  
trainingdata[, 42]   -0.89789    1.27691  -0.703   0.5207  
trainingdata[, 43]   19.29205   21.91069   0.880   0.4283  
trainingdata[, 44]   21.34151   13.93432   1.532   0.2004  
trainingdata[, 45]    9.92359    6.50173   1.526   0.2016  
trainingdata[, 46]   -2.24118    1.70686  -1.313   0.2594  
trainingdata[, 47]    2.26942    1.48956   1.524   0.2023  
trainingdata[, 48]   -8.17901   18.45388  -0.443   0.6805  
trainingdata[, 49]    3.09849   12.70253   0.244   0.8193  
trainingdata[, 50]   -5.85536    7.12827  -0.821   0.4575  
trainingdata[, 51]   -1.35397    1.55451  -0.871   0.4329  
trainingdata[, 52]    0.83009    1.39000   0.597   0.5825  
trainingdata[, 53]  -11.09655   18.13617  -0.612   0.5737  
trainingdata[, 54]  -20.62840   16.42185  -1.256   0.2774  
trainingdata[, 55]   -8.41884    8.03990  -1.047   0.3541  
trainingdata[, 56]   -3.52379    0.90900  -3.877   0.0179 *
trainingdata[, 57]    2.53607    0.77844   3.258   0.0311 *
trainingdata[, 58]   29.92300   19.17146   1.561   0.1936  
trainingdata[, 59]    2.72723   11.77282   0.232   0.8282  
trainingdata[, 60]   -0.47467    6.36047  -0.075   0.9441  
trainingdata[, 61]   -1.21513    1.38629  -0.877   0.4302  
trainingdata[, 62]    0.51587    1.12253   0.460   0.6697  
trainingdata[, 63]   37.76207   15.89594   2.376   0.0764 .
trainingdata[, 64]   20.67804   11.90178   1.737   0.1573  
trainingdata[, 65]   -4.56224    7.71534  -0.591   0.5861  
trainingdata[, 66]   -0.15902    0.97083  -0.164   0.8778  
trainingdata[, 67]    0.13616    0.84303   0.162   0.8795  
trainingdata[, 68]  -13.85944   16.14992  -0.858   0.4392  
trainingdata[, 69]   -7.52681    9.70576  -0.775   0.4813  
trainingdata[, 70]   -4.03959    8.56618  -0.472   0.6618  
trainingdata[, 71]    0.73697    1.10183   0.669   0.5402  
trainingdata[, 72]   -0.14657    0.82586  -0.177   0.8678  
trainingdata[, 73]   -8.07666   16.81443  -0.480   0.6561  
trainingdata[, 74]  -13.66979   10.44041  -1.309   0.2606  
trainingdata[, 75]  -13.66806    8.67711  -1.575   0.1903  
trainingdata[, 76]   -0.49423    1.17923  -0.419   0.6967  
trainingdata[, 77]    0.70007    0.97571   0.717   0.5127  
trainingdata[, 78]  -29.85465   16.98646  -1.758   0.1537  
trainingdata[, 79]   -4.46772   12.37300  -0.361   0.7363  
trainingdata[, 80]    5.32386   10.85437   0.490   0.6495  
trainingdata[, 81]   -1.06471    1.03167  -1.032   0.3604  
trainingdata[, 82]    1.16063    0.77367   1.500   0.2080  
trainingdata[, 83]  -24.03518   23.59099  -1.019   0.3659  
trainingdata[, 84]  -18.03080   13.09731  -1.377   0.2406  
trainingdata[, 85]  -12.57102    7.03553  -1.787   0.1485  
trainingdata[, 86]    0.95655    1.06505   0.898   0.4199  
trainingdata[, 87]   -0.53236    0.86690  -0.614   0.5724  
trainingdata[, 88]  -22.67906   14.80298  -1.532   0.2003  
trainingdata[, 89]   -6.14717   12.52298  -0.491   0.6492  
trainingdata[, 90]    5.16729   10.08754   0.512   0.6355  
trainingdata[, 91]    0.42874    1.13496   0.378   0.7248  
trainingdata[, 92]    0.49509    0.82445   0.601   0.5805  
trainingdata[, 93]   17.17446   16.41242   1.046   0.3544  
trainingdata[, 94]    2.31326   11.83393   0.195   0.8545  
trainingdata[, 95]   -2.29964    8.13889  -0.283   0.7915  
trainingdata[, 96]    1.88716    1.69700   1.112   0.3284  
trainingdata[, 97]   -1.45781    1.36560  -1.068   0.3459  
trainingdata[, 98]   17.61636   18.82399   0.936   0.4023  
trainingdata[, 99]   19.13795   14.31871   1.337   0.2523  
trainingdata[, 100]   2.29805    9.06896   0.253   0.8125  
trainingdata[, 101]   0.33347    1.60159   0.208   0.8452  
trainingdata[, 102]   0.07308    1.29494   0.056   0.9577  
trainingdata[, 103]  41.28377   23.42397   1.762   0.1528  
trainingdata[, 104]  22.78573   22.86740   0.996   0.3754  
trainingdata[, 105]   9.03470   11.60622   0.778   0.4798  
trainingdata[, 106]  -1.80905    1.73248  -1.044   0.3553  
trainingdata[, 107]   1.53194    1.44053   1.063   0.3475  
trainingdata[, 108]  47.51382   25.54762   1.860   0.1364  
trainingdata[, 109]  53.68206   20.17721   2.661   0.0564 .
trainingdata[, 110]  26.35790   11.44388   2.303   0.0826 .
trainingdata[, 111]  -4.71852    1.97800  -2.385   0.0755 .
trainingdata[, 112]   3.99685    1.60330   2.493   0.0673 .
trainingdata[, 113]  44.18591   19.91289   2.219   0.0907 .
trainingdata[, 114]  37.59905   18.34864   2.049   0.1098  
trainingdata[, 115]  16.69129   10.12409   1.649   0.1746  
trainingdata[, 116]  -4.25517    1.52350  -2.793   0.0492 *
trainingdata[, 117]   3.05193    1.27385   2.396   0.0747 .
trainingdata[, 118]   7.82834   22.20328   0.353   0.7422  
trainingdata[, 119]  14.96934   10.84492   1.380   0.2396  
trainingdata[, 120]  10.36718   10.52858   0.985   0.3805  
trainingdata[, 121]  -2.39340    1.66255  -1.440   0.2234  
trainingdata[, 122]   2.09401    1.43598   1.458   0.2185  
trainingdata[, 123] -18.44011   17.39623  -1.060   0.3489  
trainingdata[, 124] -25.66810   15.33010  -1.674   0.1694  
trainingdata[, 125]  -5.61310    9.74849  -0.576   0.5956  
trainingdata[, 126]   0.41525    1.55502   0.267   0.8026  
trainingdata[, 127]  -0.02097    1.32344  -0.016   0.9881  
trainingdata[, 128] -30.85387   19.36640  -1.593   0.1863  
trainingdata[, 129] -31.62315   19.43945  -1.627   0.1791  
trainingdata[, 130] -21.43247   11.81547  -1.814   0.1439  
trainingdata[, 131]   0.98702    1.80632   0.546   0.6138  
trainingdata[, 132]  -0.93694    1.57506  -0.595   0.5840  
trainingdata[, 133] -35.21316   14.14372  -2.490   0.0675 .
trainingdata[, 134] -42.51773   15.26953  -2.784   0.0496 *
trainingdata[, 135] -14.04521   10.60595  -1.324   0.2560  
trainingdata[, 136]   0.10142    1.55643   0.065   0.9512  
trainingdata[, 137]  -0.03256    1.34187  -0.024   0.9818  
trainingdata[, 138]  -4.24850   15.73808  -0.270   0.8006  
trainingdata[, 139] -16.34199   13.65214  -1.197   0.2974  
trainingdata[, 140]  -3.57058    7.67596  -0.465   0.6660  
trainingdata[, 141]  -0.31867    1.75431  -0.182   0.8647  
trainingdata[, 142]   0.38536    1.43765   0.268   0.8019  
trainingdata[, 143]   7.58119   16.97023   0.447   0.6782  
trainingdata[, 144]  14.22821   12.70837   1.120   0.3256  
trainingdata[, 145]  24.59181    9.82704   2.502   0.0666 .
trainingdata[, 146]  -2.48179    1.46185  -1.698   0.1648  
trainingdata[, 147]   2.07227    1.19875   1.729   0.1589  
trainingdata[, 148]  32.86064   15.28029   2.151   0.0979 .
trainingdata[, 149]  30.56321   16.16431   1.891   0.1316  
trainingdata[, 150]  15.46826   16.40712   0.943   0.3992  
trainingdata[, 151]  -1.07077    2.05403  -0.521   0.6297  
trainingdata[, 152]   0.62828    1.73350   0.362   0.7354  
trainingdata[, 153]  19.93470   11.87155   1.679   0.1684  
trainingdata[, 154]  32.75220   11.30380   2.897   0.0442 *
trainingdata[, 155]  23.31024    7.28097   3.202   0.0329 *
trainingdata[, 156]  -3.74613    1.67617  -2.235   0.0891 .
trainingdata[, 157]   3.07263    1.34456   2.285   0.0843 .
trainingdata[, 158]   3.91399   13.00768   0.301   0.7785  
trainingdata[, 159]   2.42820    9.52027   0.255   0.8113  
trainingdata[, 160] -11.06911    6.67756  -1.658   0.1727  
trainingdata[, 161]  -1.14347    1.87141  -0.611   0.5742  
trainingdata[, 162]   1.34911    1.59650   0.845   0.4457  
trainingdata[, 163] -25.21452   14.38968  -1.752   0.1546  
trainingdata[, 164]  -6.81562   15.82760  -0.431   0.6889  
trainingdata[, 165]  -9.40464   12.07794  -0.779   0.4797  
trainingdata[, 166]  -3.07671    1.39618  -2.204   0.0923 .
trainingdata[, 167]   2.74852    1.02828   2.673   0.0556 .
trainingdata[, 168]  -8.41331   16.86340  -0.499   0.6440  
trainingdata[, 169] -30.44411   11.14799  -2.731   0.0524 .
trainingdata[, 170] -14.43922    6.24400  -2.312   0.0818 .
trainingdata[, 171]  -1.67250    0.99145  -1.687   0.1669  
trainingdata[, 172]   1.47009    0.82254   1.787   0.1484  
trainingdata[, 173]   0.92606   14.94379   0.062   0.9536  
trainingdata[, 174]   4.67154   11.56964   0.404   0.7070  
trainingdata[, 175]   7.89914    8.09195   0.976   0.3843  
trainingdata[, 176]  -3.45814    1.34460  -2.572   0.0619 .
trainingdata[, 177]   2.91255    1.09942   2.649   0.0570 .
trainingdata[, 178]   3.70367   16.19114   0.229   0.8303  
trainingdata[, 179]   2.28325   13.50300   0.169   0.8739  
trainingdata[, 180]   7.23051   10.75090   0.673   0.5381  
trainingdata[, 181]  -3.46948    1.44199  -2.406   0.0739 .
trainingdata[, 182]   2.62595    1.14383   2.296   0.0833 .
trainingdata[, 183]  12.65630   15.19197   0.833   0.4516  
trainingdata[, 184]  24.06080   13.54349   1.777   0.1503  
trainingdata[, 185]  10.54205    7.65734   1.377   0.2406  
trainingdata[, 186]  -2.81335    1.52196  -1.849   0.1382  
trainingdata[, 187]   1.91397    1.27973   1.496   0.2091  
trainingdata[, 188]   5.17052   19.23557   0.269   0.8014  
trainingdata[, 189]  10.33531   11.41241   0.906   0.4164  
trainingdata[, 190]  -0.36780    6.50566  -0.057   0.9576  
trainingdata[, 191]  -1.33684    0.97125  -1.376   0.2407  
trainingdata[, 192]   1.23019    0.86704   1.419   0.2289  
trainingdata[, 193]  -3.53490   21.27238  -0.166   0.8761  
trainingdata[, 194]  -7.88146   13.33942  -0.591   0.5864  
trainingdata[, 195] -15.16809    9.85036  -1.540   0.1984  
trainingdata[, 196]   0.17923    1.29610   0.138   0.8967  
trainingdata[, 197]   0.38814    1.03907   0.374   0.7277  
trainingdata[, 198] -41.27508   15.55099  -2.654   0.0567 .
trainingdata[, 199] -33.07604   14.57878  -2.269   0.0858 .
 [ reached getOption("max.print") -- omitted 101 rows ]
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1.629 on 4 degrees of freedom
Multiple R-squared:  0.9994,	Adjusted R-squared:  0.9555 
F-statistic: 22.75 on 300 and 4 DF,  p-value: 0.003667


k = 5
Residuals:
    Min      1Q  Median      3Q     Max 
-8.4321 -1.2012  0.0983  1.4225  7.7487 

Coefficients:
                   Estimate Std. Error t value Pr(>|t|)    
(Intercept)         1.97912    0.92849   2.132 0.033774 *  
trainingdata[, 1]   0.06154    0.20796   0.296 0.767484    
trainingdata[, 2]   0.08804    0.16166   0.545 0.586375    
trainingdata[, 3]   1.00274    2.16807   0.463 0.644020    
trainingdata[, 4]   2.82859    2.51339   1.125 0.261223    
trainingdata[, 5]   2.15584    2.21789   0.972 0.331741    
trainingdata[, 6]  -0.21283    0.23015  -0.925 0.355758    
trainingdata[, 7]   0.10226    0.17375   0.589 0.556585    
trainingdata[, 8]   0.23487    3.03134   0.077 0.938288    
trainingdata[, 9]   1.79697    3.47307   0.517 0.605219    
trainingdata[, 10]  1.51482    3.04132   0.498 0.618756    
trainingdata[, 11]  0.36423    0.22953   1.587 0.113489    
trainingdata[, 12] -0.14128    0.17353  -0.814 0.416124    
trainingdata[, 13] -1.79664    3.03554  -0.592 0.554340    
trainingdata[, 14] -0.47467    3.47334  -0.137 0.891381    
trainingdata[, 15] -0.71116    3.03920  -0.234 0.815131    
trainingdata[, 16]  0.06412    0.23037   0.278 0.780933    
trainingdata[, 17] -0.29836    0.17339  -1.721 0.086217 .  
trainingdata[, 18]  0.18465    3.03793   0.061 0.951569    
trainingdata[, 19] -1.88871    3.47822  -0.543 0.587485    
trainingdata[, 20] -1.32923    3.03772  -0.438 0.661977    
trainingdata[, 21]  0.25064    0.21775   1.151 0.250543    
trainingdata[, 22]  0.54271    0.16239   3.342 0.000926 ***
trainingdata[, 23]  0.22972    2.17762   0.105 0.916050    
trainingdata[, 24] -1.02770    2.48987  -0.413 0.680052    
trainingdata[, 25]  0.11623    2.19913   0.053 0.957881    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 2.447 on 334 degrees of freedom
Multiple R-squared:  0.9294,	Adjusted R-squared:  0.9241 
F-statistic: 175.7 on 25 and 334 DF,  p-value: < 2.2e-16    

k=7

Residuals:
    Min      1Q  Median      3Q     Max 
-8.6695 -1.2403 -0.0826  1.3973  8.3344 

Coefficients:
                   Estimate Std. Error t value Pr(>|t|)    
(Intercept)         2.87988    1.02949   2.797 0.005462 ** 
trainingdata[, 1]  -0.35120    0.20546  -1.709 0.088344 .  
trainingdata[, 2]   0.41065    0.15925   2.579 0.010363 *  
trainingdata[, 3]   0.62167    2.12872   0.292 0.770443    
trainingdata[, 4]   3.05822    2.46980   1.238 0.216526    
trainingdata[, 5]   2.48729    2.18916   1.136 0.256726    
trainingdata[, 6]   0.22059    0.22725   0.971 0.332423    
trainingdata[, 7]  -0.23752    0.17169  -1.383 0.167489    
trainingdata[, 8]  -1.94274    2.96959  -0.654 0.513442    
trainingdata[, 9]  -0.31276    3.40421  -0.092 0.926855    
trainingdata[, 10]  0.57075    2.98366   0.191 0.848418    
trainingdata[, 11] -0.09735    0.22841  -0.426 0.670243    
trainingdata[, 12]  0.20550    0.17224   1.193 0.233710    
trainingdata[, 13]  2.03487    2.97354   0.684 0.494263    
trainingdata[, 14]  1.03348    3.40218   0.304 0.761500    
trainingdata[, 15] -0.19690    2.98725  -0.066 0.947489    
trainingdata[, 16] -0.19322    0.23005  -0.840 0.401581    
trainingdata[, 17]  0.09455    0.17351   0.545 0.586202    
trainingdata[, 18]  0.40894    2.97745   0.137 0.890843    
trainingdata[, 19]  0.93734    3.40754   0.275 0.783433    
trainingdata[, 20]  0.78798    2.98561   0.264 0.792006    
trainingdata[, 21]  0.32078    0.22820   1.406 0.160792    
trainingdata[, 22] -0.12649    0.17246  -0.733 0.463813    
trainingdata[, 23] -1.05644    2.97992  -0.355 0.723182    
trainingdata[, 24]  0.07650    3.41242   0.022 0.982127    
trainingdata[, 25] -0.07907    2.98824  -0.026 0.978905    
trainingdata[, 26]  0.08501    0.22688   0.375 0.708152    
trainingdata[, 27] -0.32203    0.17082  -1.885 0.060296 .  
trainingdata[, 28]  0.41932    2.98007   0.141 0.888189    
trainingdata[, 29] -1.96415    3.41507  -0.575 0.565597    
trainingdata[, 30] -1.53414    2.98364  -0.514 0.607477    
trainingdata[, 31]  0.14506    0.21663   0.670 0.503592    
trainingdata[, 32]  0.59334    0.16125   3.680 0.000274 ***
trainingdata[, 33] -0.21168    2.14157  -0.099 0.921324    
trainingdata[, 34] -1.28241    2.44338  -0.525 0.600048    
trainingdata[, 35] -0.10980    2.15864  -0.051 0.959465    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 2.395 on 322 degrees of freedom
Multiple R-squared:  0.9339,	Adjusted R-squared:  0.9267 
F-statistic: 129.9 on 35 and 322 DF,  p-value: < 2.2e-16


k=3

Residuals:
    Min      1Q  Median      3Q     Max 
-8.1450 -1.2085  0.1356  1.4504  7.7498 

Coefficients:
                   Estimate Std. Error t value Pr(>|t|)   
(Intercept)          1.6078     0.9992   1.609   0.1087   
trainingdata[, 1]    0.3464     0.2206   1.570   0.1175   
trainingdata[, 2]   -0.1176     0.1719  -0.684   0.4946   
trainingdata[, 3]   -4.0557     4.4135  -0.919   0.3589   
trainingdata[, 4]    0.8896     3.5988   0.247   0.8049   
trainingdata[, 5]    0.9205     2.5914   0.355   0.7227   
trainingdata[, 6]    0.1964     0.2456   0.799   0.4247   
trainingdata[, 7]   -0.3472     0.1868  -1.859   0.0640 . 
trainingdata[, 8]    6.3817     6.1966   1.030   0.3039   
trainingdata[, 9]    2.9096     4.9967   0.582   0.5608   
trainingdata[, 10]   1.2585     3.5566   0.354   0.7237   
trainingdata[, 11]   0.2538     0.2308   1.100   0.2723   
trainingdata[, 12]   0.5363     0.1736   3.090   0.0022 **
trainingdata[, 13]  -2.9960     4.4088  -0.680   0.4973   
trainingdata[, 14]  -2.9720     3.5660  -0.833   0.4053   
trainingdata[, 15]  -0.7031     2.5516  -0.276   0.7831   
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 2.471 on 289 degrees of freedom
Multiple R-squared:  0.9308,	Adjusted R-squared:  0.9272 
F-statistic: 259.1 on 15 and 289 DF,  p-value: < 2.2e-16





Atmospheric Stuff now

k = 3
Residuals:
    Min      1Q  Median      3Q     Max 
-10.067  -1.782   0.091   1.962   9.253 

Coefficients:
                   Estimate Std. Error t value Pr(>|t|)    
(Intercept)         0.07319    1.10620   0.066   0.9473    
trainingdata[, 1]   0.54128    0.27620   1.960   0.0508 .  
trainingdata[, 2]  -0.20195    0.21593  -0.935   0.3503    
trainingdata[, 3]  -0.78688    2.93231  -0.268   0.7886    
trainingdata[, 4]   4.21856    3.38474   1.246   0.2135    
trainingdata[, 5]   1.77068    2.98470   0.593   0.5534    
trainingdata[, 6]   0.01175    0.30585   0.038   0.9694    
trainingdata[, 7]  -0.34837    0.23040  -1.512   0.1314    
trainingdata[, 8]   0.02070    4.11050   0.005   0.9960    
trainingdata[, 9]  -1.62983    4.71418  -0.346   0.7298    
trainingdata[, 10]  0.26755    4.11411   0.065   0.9482    
trainingdata[, 11] -0.08790    0.29112  -0.302   0.7629    
trainingdata[, 12]  1.04640    0.21707   4.821 2.15e-06 ***
trainingdata[, 13] -0.34226    2.94653  -0.116   0.9076    
trainingdata[, 14] -1.45096    3.37178  -0.430   0.6672    
trainingdata[, 15] -0.14586    2.96331  -0.049   0.9608    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 3.323 on 346 degrees of freedom
Multiple R-squared:  0.9147,	Adjusted R-squared:  0.911 
F-statistic: 247.2 on 15 and 346 DF,  p-value: < 2.2e-16


k = 4
Residuals:
     Min       1Q   Median       3Q      Max 
-10.2490  -1.8264   0.1315   1.9779   9.3617 

Coefficients:
                   Estimate Std. Error t value Pr(>|t|)    
(Intercept)         0.40039    1.18376   0.338    0.735    
trainingdata[, 1]   0.07902    0.28061   0.282    0.778    
trainingdata[, 2]   0.04296    0.21810   0.197    0.844    
trainingdata[, 3]   1.92144    2.93517   0.655    0.513    
trainingdata[, 4]   4.76311    3.39310   1.404    0.161    
trainingdata[, 5]   3.82184    3.00091   1.274    0.204    
trainingdata[, 6]   0.33597    0.30864   1.089    0.277    
trainingdata[, 7]  -0.14277    0.23367  -0.611    0.542    
trainingdata[, 8]  -3.19214    4.10970  -0.777    0.438    
trainingdata[, 9]  -0.20088    4.71237  -0.043    0.966    
trainingdata[, 10] -1.45951    4.11947  -0.354    0.723    
trainingdata[, 11]  0.01022    0.30869   0.033    0.974    
trainingdata[, 12] -0.31467    0.23228  -1.355    0.176    
trainingdata[, 13]  0.45330    4.11686   0.110    0.912    
trainingdata[, 14] -1.61358    4.71196  -0.342    0.732    
trainingdata[, 15] -0.02720    4.11615  -0.007    0.995    
trainingdata[, 16] -0.14140    0.29443  -0.480    0.631    
trainingdata[, 17]  1.06423    0.21941   4.850 1.88e-06 ***
trainingdata[, 18] -0.05949    2.94957  -0.020    0.984    
trainingdata[, 19] -1.69012    3.37191  -0.501    0.617    
trainingdata[, 20] -0.43923    2.97042  -0.148    0.883    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 3.32 on 340 degrees of freedom
Multiple R-squared:  0.9157,	Adjusted R-squared:  0.9108 
F-statistic: 184.7 on 20 and 340 DF,  p-value: < 2.2e-16

k = 5
Residuals:
   Min     1Q Median     3Q    Max 
-9.189 -1.721  0.080  1.947  9.488 

Coefficients:
                    Estimate Std. Error t value Pr(>|t|)    
(Intercept)         2.139756   2.218763   0.964  0.33557    
trainingdata[, 1]   0.089252   0.294432   0.303  0.76198    
trainingdata[, 2]   0.097539   0.225126   0.433  0.66511    
trainingdata[, 3]   0.623967   2.869628   0.217  0.82800    
trainingdata[, 4]   3.181603   3.321697   0.958  0.33887    
trainingdata[, 5]   1.615930   2.935901   0.550  0.58242    
trainingdata[, 6]  -1.745380   1.402977  -1.244  0.21438    
trainingdata[, 7]   0.007949   0.041865   0.190  0.84952    
trainingdata[, 8]  -0.137899   0.334256  -0.413  0.68020    
trainingdata[, 9]   0.047918   0.248073   0.193  0.84695    
trainingdata[, 10] -1.306549   4.056087  -0.322  0.74757    
trainingdata[, 11]  1.338086   4.624153   0.289  0.77248    
trainingdata[, 12]  1.696343   4.042285   0.420  0.67502    
trainingdata[, 13]  1.927752   1.612845   1.195  0.23286    
trainingdata[, 14] -0.018719   0.043937  -0.426  0.67036    
trainingdata[, 15]  0.086430   0.336592   0.257  0.79751    
trainingdata[, 16]  0.058535   0.249936   0.234  0.81498    
trainingdata[, 17]  1.304018   4.050419   0.322  0.74770    
trainingdata[, 18]  1.955680   4.640696   0.421  0.67373    
trainingdata[, 19] -0.053754   4.028285  -0.013  0.98936    
trainingdata[, 20] -3.074064   1.613372  -1.905  0.05762 .  
trainingdata[, 21]  0.023037   0.044539   0.517  0.60535    
trainingdata[, 22] -0.151863   0.340797  -0.446  0.65618    
trainingdata[, 23] -0.135704   0.252845  -0.537  0.59184    
trainingdata[, 24] -1.862332   3.997353  -0.466  0.64161    
trainingdata[, 25] -5.055853   4.619236  -1.095  0.27454    
trainingdata[, 26] -3.315750   4.004405  -0.828  0.40827    
trainingdata[, 27] -0.236413   1.599553  -0.148  0.88259    
trainingdata[, 28]  0.088917   0.044240   2.010  0.04527 *  
trainingdata[, 29]  0.397331   0.314085   1.265  0.20677    
trainingdata[, 30]  0.607672   0.234312   2.593  0.00993 ** 
trainingdata[, 31]  0.791153   2.847749   0.278  0.78133    
trainingdata[, 32] -0.089708   3.308696  -0.027  0.97839    
trainingdata[, 33]  1.464210   2.913068   0.503  0.61556    
trainingdata[, 34]  1.723593   1.426995   1.208  0.22799    
trainingdata[, 35] -0.195210   0.039713  -4.915 1.41e-06 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 3.181 on 324 degrees of freedom
Multiple R-squared:  0.9259,	Adjusted R-squared:  0.9178 
F-statistic: 115.6 on 35 and 324 DF,  p-value: < 2.2e-16

k = 3 Humid + Wind
Residuals:
    Min      1Q  Median      3Q     Max 
-9.4883 -1.6468 -0.0977  1.8531  9.4293 

Coefficients:
                   Estimate Std. Error t value Pr(>|t|)    
(Intercept)         2.04244    1.76690   1.156   0.2485    
trainingdata[, 1]   0.28904    0.28920   0.999   0.3183    
trainingdata[, 2]  -0.05701    0.22170  -0.257   0.7972    
trainingdata[, 3]   1.15323    2.84831   0.405   0.6858    
trainingdata[, 4]   5.93978    3.28894   1.806   0.0718 .  
trainingdata[, 5]   2.56006    2.89772   0.883   0.3776    
trainingdata[, 6]  -2.59588    1.38477  -1.875   0.0617 .  
trainingdata[, 7]   0.02604    0.04145   0.628   0.5302    
trainingdata[, 8]  -0.13718    0.32850  -0.418   0.6765    
trainingdata[, 9]  -0.13519    0.24350  -0.555   0.5791    
trainingdata[, 10] -2.50901    3.98976  -0.629   0.5299    
trainingdata[, 11] -4.56994    4.60253  -0.993   0.3215    
trainingdata[, 12] -2.40899    3.99262  -0.603   0.5467    
trainingdata[, 13] -0.22712    1.57395  -0.144   0.8853    
trainingdata[, 14]  0.07378    0.04304   1.714   0.0874 .  
trainingdata[, 15]  0.45221    0.30694   1.473   0.1416    
trainingdata[, 16]  0.59026    0.22909   2.577   0.0104 *  
trainingdata[, 17]  0.42971    2.84211   0.151   0.8799    
trainingdata[, 18] -0.21785    3.30419  -0.066   0.9475    
trainingdata[, 19]  1.36730    2.88811   0.473   0.6362    
trainingdata[, 20]  1.04947    1.40600   0.746   0.4559    
trainingdata[, 21] -0.20865    0.03899  -5.352 1.61e-07 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 3.191 on 340 degrees of freedom
Multiple R-squared:  0.9226,	Adjusted R-squared:  0.9178 
F-statistic: 193.1 on 21 and 340 DF,  p-value: < 2.2e-16

k = 4 Humid + wind
Residuals:
    Min      1Q  Median      3Q     Max 
-9.8460 -1.6234 -0.0444  1.7954  9.5415 

Coefficients:
                    Estimate Std. Error t value Pr(>|t|)    
(Intercept)         1.952834   2.004330   0.974   0.3306    
trainingdata[, 1]   0.022385   0.294421   0.076   0.9394    
trainingdata[, 2]   0.066285   0.224682   0.295   0.7682    
trainingdata[, 3]   0.271115   2.883222   0.094   0.9251    
trainingdata[, 4]   3.817211   3.327780   1.147   0.2522    
trainingdata[, 5]   2.371571   2.950926   0.804   0.4222    
trainingdata[, 6]   1.029899   1.402544   0.734   0.4633    
trainingdata[, 7]  -0.009449   0.041971  -0.225   0.8220    
trainingdata[, 8]   0.128515   0.332796   0.386   0.6996    
trainingdata[, 9]  -0.021277   0.247331  -0.086   0.9315    
trainingdata[, 10]  0.533399   4.065295   0.131   0.8957    
trainingdata[, 11]  2.308909   4.645495   0.497   0.6195    
trainingdata[, 12]  0.577652   4.041106   0.143   0.8864    
trainingdata[, 13] -3.326704   1.603118  -2.075   0.0387 *  
trainingdata[, 14]  0.021495   0.043958   0.489   0.6252    
trainingdata[, 15] -0.114265   0.335972  -0.340   0.7340    
trainingdata[, 16] -0.128239   0.248868  -0.515   0.6067    
trainingdata[, 17] -2.271407   4.014985  -0.566   0.5720    
trainingdata[, 18] -4.549401   4.640131  -0.980   0.3276    
trainingdata[, 19] -2.627813   4.016606  -0.654   0.5134    
trainingdata[, 20] -0.116781   1.598665  -0.073   0.9418    
trainingdata[, 21]  0.082093   0.044085   1.862   0.0635 .  
trainingdata[, 22]  0.409679   0.314848   1.301   0.1941    
trainingdata[, 23]  0.611146   0.234944   2.601   0.0097 ** 
trainingdata[, 24]  0.742719   2.861359   0.260   0.7954    
trainingdata[, 25] -0.270751   3.324822  -0.081   0.9351    
trainingdata[, 26]  1.279350   2.921249   0.438   0.6617    
trainingdata[, 27]  1.281704   1.423301   0.901   0.3685    
trainingdata[, 28] -0.204232   0.039672  -5.148 4.52e-07 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 3.202 on 332 degrees of freedom
Multiple R-squared:  0.9235,	Adjusted R-squared:  0.917 
F-statistic:   143 on 28 and 332 DF,  p-value: < 2.2e-16

k=7
Residuals:
    Min      1Q  Median      3Q     Max 
-8.7671 -1.5829 -0.1173  1.8649  9.2268 

Coefficients:
                    Estimate Std. Error t value Pr(>|t|)    
(Intercept)         4.344201   2.655833   1.636  0.10292    
trainingdata[, 1]  -0.242883   0.295377  -0.822  0.41155    
trainingdata[, 2]   0.333552   0.225756   1.477  0.14057    
trainingdata[, 3]  -0.264211   2.869252  -0.092  0.92669    
trainingdata[, 4]   3.417370   3.319435   1.030  0.30405    
trainingdata[, 5]   3.323143   2.947494   1.127  0.26043    
trainingdata[, 6]  -2.402822   1.431908  -1.678  0.09435 .  
trainingdata[, 7]  -0.043092   0.041897  -1.029  0.30451    
trainingdata[, 8]   0.259760   0.334457   0.777  0.43795    
trainingdata[, 9]  -0.270639   0.248817  -1.088  0.27758    
trainingdata[, 10] -1.061226   4.049577  -0.262  0.79345    
trainingdata[, 11] -0.290625   4.594082  -0.063  0.94960    
trainingdata[, 12] -0.735721   4.025005  -0.183  0.85508    
trainingdata[, 13] -0.749547   1.636162  -0.458  0.64719    
trainingdata[, 14]  0.051459   0.043930   1.171  0.24235    
trainingdata[, 15] -0.019557   0.339600  -0.058  0.95411    
trainingdata[, 16]  0.198211   0.252280   0.786  0.43266    
trainingdata[, 17]  1.620043   4.042353   0.401  0.68887    
trainingdata[, 18]  1.540262   4.610510   0.334  0.73855    
trainingdata[, 19]  0.317346   4.033349   0.079  0.93734    
trainingdata[, 20] -0.122882   1.634131  -0.075  0.94011    
trainingdata[, 21] -0.004726   0.044580  -0.106  0.91565    
trainingdata[, 22] -0.242625   0.344958  -0.703  0.48237    
trainingdata[, 23]  0.108400   0.256459   0.423  0.67283    
trainingdata[, 24] -0.923733   4.039512  -0.229  0.81927    
trainingdata[, 25]  0.124075   4.618541   0.027  0.97859    
trainingdata[, 26]  0.430125   4.032301   0.107  0.91512    
trainingdata[, 27]  1.173228   1.630805   0.719  0.47243    
trainingdata[, 28] -0.011065   0.044915  -0.246  0.80557    
trainingdata[, 29]  0.077953   0.342281   0.228  0.82000    
trainingdata[, 30]  0.050619   0.254894   0.199  0.84272    
trainingdata[, 31]  2.105395   4.031799   0.522  0.60191    
trainingdata[, 32]  2.387553   4.619084   0.517  0.60560    
trainingdata[, 33]  0.332931   4.012641   0.083  0.93393    
trainingdata[, 34] -2.331778   1.628084  -1.432  0.15309    
trainingdata[, 35]  0.030928   0.044906   0.689  0.49152    
trainingdata[, 36] -0.146693   0.340993  -0.430  0.66736    
trainingdata[, 37] -0.141724   0.253516  -0.559  0.57654    
trainingdata[, 38] -1.773753   3.991349  -0.444  0.65707    
trainingdata[, 39] -5.475691   4.597856  -1.191  0.23460    
trainingdata[, 40] -3.046357   3.980841  -0.765  0.44471    
trainingdata[, 41] -0.023646   1.619922  -0.015  0.98836    
trainingdata[, 42]  0.072902   0.044486   1.639  0.10228    
trainingdata[, 43]  0.258318   0.316948   0.815  0.41569    
trainingdata[, 44]  0.674856   0.236205   2.857  0.00457 ** 
trainingdata[, 45]  0.019293   2.854372   0.007  0.99461    
trainingdata[, 46] -0.115525   3.291855  -0.035  0.97203    
trainingdata[, 47]  0.811801   2.898116   0.280  0.77958    
trainingdata[, 48]  1.017824   1.450723   0.702  0.48346    
trainingdata[, 49] -0.194763   0.039987  -4.871 1.78e-06 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 3.153 on 308 degrees of freedom
Multiple R-squared:  0.9299,	Adjusted R-squared:  0.9188 
F-statistic:  83.4 on 49 and 308 DF,  p-value: < 2.2e-16